"""
Test scenario runner for component integration tests.
"""

import socket
import time
from pathlib import Path
from subprocess import PIPE, Popen

import pytest
from testing_utils import BuildTools, CargoTools, LogContainer, Scenario, ScenarioResult


class NetHelper:
    @staticmethod
    def connection_builder(
        ip: str = "127.0.0.1", port: int = 7878, timeout: float | None = 3.0
    ) -> socket.socket:
        """
        Create and return a socket connected to the server.

        Parameters
        ----------
        ip : str
            IP address of the server.
        port : int
            Port number of the server.
        timeout : float | None
            Connection timeout in seconds. 0 for non-blocking mode, None for blocking mode.
        """
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.settimeout(timeout)
        s.connect((ip, port))
        return s


class ResultCode:
    """
    Test scenario exit codes.
    """

    SUCCESS = 0
    PANIC = 101
    SIGABRT = -6
    SIGKILL = -9
    SIGSEGV = -11


class CitScenario(Scenario):
    """
    CIT test scenario definition.
    """

    @pytest.fixture(scope="class")
    def build_tools(self, *args, **kwargs) -> BuildTools:
        """
        Build tools used to handle test scenario.
        """
        return CargoTools()

    def expect_command_failure(self, *args, **kwargs) -> bool:
        """
        Expect command failure (e.g., non-zero return code or hang).
        """
        return False

    @pytest.fixture(scope="class")
    def results(
        self,
        command: list[str],
        execution_timeout: float,
        *args,
        **kwargs,
    ) -> ScenarioResult:
        result = self._run_command(command, execution_timeout, args, kwargs)
        success = result.return_code == 0 and not result.hang
        if self.expect_command_failure() and success:
            raise RuntimeError(f"Command execution succeeded unexpectedly: {result=}")
        if not self.expect_command_failure() and not success:
            raise RuntimeError(f"Command execution failed unexpectedly: {result=}")
        return result

    @pytest.fixture(scope="class")
    def logs_target(self, target_path: Path, logs: LogContainer) -> LogContainer:
        """
        Logs with messages generated strictly by the tested code.

        Parameters
        ----------
        target_path : Path
            Path to test scenario executable.
        logs : LogContainer
            Unfiltered logs.
        """
        return logs.get_logs(field="target", pattern=f"{target_path.name}.*")

    @pytest.fixture(scope="class")
    def logs_info_level(self, logs_target: LogContainer) -> LogContainer:
        """
        Logs with messages with INFO level.

        Parameters
        ----------
        logs_target : LogContainer
            Logs with messages generated strictly by the tested code.
        """
        return logs_target.get_logs(field="level", value="INFO")

    @pytest.fixture(autouse=True)
    def print_to_report(
        self,
        request: pytest.FixtureRequest,
        logs: LogContainer,
        logs_target: LogContainer,
    ) -> None:
        """
        Print traces to stdout.

        Allowed "--traces" values:
        - "none" - show no traces.
        - "target" - show traces generated by test code.
        - "all" - show all traces.

        Parameters
        ----------
        request : FixtureRequest
            Test request built-in fixture.
        logs : LogContainer
            Test scenario execution logs.
        logs_target : LogContainer
            Logs with messages generated strictly by the tested code.
        """
        traces_param = request.config.getoption("--traces")
        match traces_param:
            case "all":
                traces = logs
            case "target":
                traces = logs_target
            case "none":
                traces = LogContainer()
            case _:
                raise RuntimeError(f'Invalid "--traces" value: {traces_param}')

        for trace in traces:
            print(trace)


class CitContinousScenario(Scenario):
    """
    CIT test scenario definition for net testing.
    It requires binary with the server to be running for the duration of the tests.
    """

    @pytest.fixture(scope="class")
    def build_tools(self, *args, **kwargs) -> BuildTools:
        """
        Build tools used to handle test scenario.
        """
        return CargoTools()

    @pytest.fixture(scope="class")
    def results(
        self,
        process,
        execution_timeout: float,
        *args,
        **kwargs,
    ):
        pass

    @pytest.fixture(scope="class")
    def logs(self, results, *args, **kwargs):
        pass

    @pytest.fixture(scope="class", autouse=True)
    def server(self, command: list[str], *args, **kwargs):
        """
        Start the server process and terminate it after tests.
        """
        proc = Popen(command, stdout=PIPE, stderr=PIPE, text=True)
        time.sleep(0.5)  # give the server half a second to start
        yield proc
        proc.terminate()
